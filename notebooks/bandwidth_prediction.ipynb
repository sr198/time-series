{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "ELzES3IF8ypd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "E1mYcd4_8egc"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np            # For numerical operations and linear algebra, such as array and matrix manipulations\n",
        "import pandas as pd           # For data processing, including data manipulation and reading/writing CSV files (e.g., pd.read_csv)\n",
        "import optuna                 # For automated hyperparameter tuning, which optimizes model parameters to improve accuracy\n",
        "import logging                # For controlling and managing log outputs, especially useful in suppressing or capturing log messages\n",
        "import seaborn as sns         # For data visualization, particularly for creating aesthetically pleasing statistical graphics\n",
        "import matplotlib.pyplot as plt  # For general-purpose plotting, allows for custom charts and visualizations\n",
        "\n",
        "import xgboost as xgb         # XGBoost library, used for efficient gradient boosting, which is popular for structured/tabular data\n",
        "from xgboost import plot_importance, plot_tree  # Additional XGBoost functions for visualizing feature importance and decision trees\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error  # Performance metrics for model evaluation, particularly useful for regression tasks\n",
        "\n",
        "# Set color palette and style for visualizations\n",
        "color_pal = sns.color_palette()    # Define a color palette for consistent styling across plots\n",
        "plt.style.use('fivethirtyeight')   # Set plot style to 'fivethirtyeight' for a clean and professional look"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('sample_data/internet_details.csv')\n",
        "# Keep only required columns\n",
        "df = df[['startdate', 'item', 'service_type', 'bandwidth_in_gbps', 'peak_bandwidth_utilization']]\n",
        "df = df.set_index(\"startdate\")\n",
        "df.index = pd.to_datetime(df.index)\n"
      ],
      "metadata": {
        "id": "0vLx3Vi-86xN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "aQNzvejA9vV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "DS-7FWah90C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets test for Google/Cache combination\n",
        "df_google = df[(df['item'] == 'Google') &\n",
        "               (df['service_type'] == 'cache')]\n",
        "\n",
        "# Sort by date\n",
        "df_google = df_google.sort_values('startdate')"
      ],
      "metadata": {
        "id": "SaPYjdyE_Wmw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_google.head()"
      ],
      "metadata": {
        "id": "Q9vM06wD_Zaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_google.tail()"
      ],
      "metadata": {
        "id": "GkiWHf34_mM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_google.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odgWT_TtWsUu",
        "outputId": "d48ca890-831b-40f3-af3a-7a11965cdfa2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "336"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the peak bandwidth utilization\n",
        "ax = df_google['peak_bandwidth_utilization'].plot(\n",
        "    style=\".\",                    # Use dots to represent each data point on the plot\n",
        "    figsize=(15, 5),              # Set the figure size to 15 inches wide by 5 inches tall\n",
        "    color=color_pal[0],           # Use the first color from the color palette for the plot points\n",
        "    title=\"Google Cache usage/Gbps\" # Set the title of the plot to indicate the data being displayed\n",
        ")\n",
        "\n",
        "# Add axis labels\n",
        "ax.set_xlabel(\"Datetime\")\n",
        "ax.set_ylabel(\"Bandwidth Consumption (Gbps)\")\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5-W2tonB_xeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into training and testing sets based on a date condition\n",
        "\n",
        "train = df_google.loc[df_google.index < '2025-08-22']\n",
        "test = df_google.loc[df_google.index >= '2025-08-22']\n",
        "\n",
        "print(f\"Train set shape: {train.shape}\")\n",
        "print(f\"Test set shape: {test.shape}\")\n",
        "\n",
        "# Set up the figure and axis\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "\n",
        "# Plot training and test sets with customized colors\n",
        "train.plot(ax=ax, label='Training Set', color='blue', linewidth=2)\n",
        "test.plot(ax=ax, label='Test Set', color='orange', linewidth=2)\n",
        "\n",
        "# Add vertical line for split date with annotation\n",
        "split_date = '2025-08-22'\n",
        "ax.axvline(split_date, color='black', linestyle='--', linewidth=1.5)\n",
        "ax.text(split_date, ax.get_ylim()[1] * 0.9, 'Train/Test Split',\n",
        "        rotation=90, color='black', verticalalignment='center', fontweight='bold')\n",
        "\n",
        "# Customize title and labels\n",
        "ax.set_title('Data Train/Test Split', fontsize=16, fontweight='bold')\n",
        "ax.set_xlabel('Date', fontsize=14)\n",
        "ax.set_ylabel('Peak Bandwidth Usage', fontsize=14)\n",
        "\n",
        "# Display grid for better readability\n",
        "ax.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
        "\n",
        "# Add legend and show plot\n",
        "ax.legend(['Training Set', 'Test Set'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2-qW4oLFst3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame based on the date range\n",
        "filtered_df = df_google.loc[(df_google.index > \"2025-06-01\") & (df_google.index < \"2025-08-01\")]\n",
        "# Apply a 7-day rolling average to smooth the data\n",
        "smoothed_df = filtered_df[\"peak_bandwidth_utilization\"].rolling(window=7, center=True).mean()\n",
        "\n",
        "# Plot the smoothed data\n",
        "ax = smoothed_df.plot(figsize=(15, 5), title=\"Bandwidth usage from 2025-06-01 to 2025-08-01\", color=color_pal[0])\n",
        "\n",
        "# Add additional plot information for clarity\n",
        "ax.set_xlabel(\"Date\")  # X-axis label\n",
        "ax.set_ylabel(\"Bandwidth Usage\")  # Y-axis label\n",
        "ax.grid(True)  # Enable grid for better readability\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tnPZxLoMtbhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_features(df):\n",
        "    # Existing features\n",
        "    df = df.copy()\n",
        "    df[\"dayofweek\"] = df.index.dayofweek\n",
        "    df[\"month\"] = df.index.month\n",
        "\n",
        "    # Additional features\n",
        "    df[\"dayofmonth\"] = df.index.day              # Day of the month (1 to 31)\n",
        "    df[\"is_weekend\"] = df.index.dayofweek == 5    # Binary feature for Saturday (1 if Saturday, else 0)\n",
        "    df[\"is_friday\"] = df.index.dayofweek == 4     # Binay feature for Friday\n",
        "    df[\"is_month_start\"] = df.index.is_month_start # Binary feature for start of month\n",
        "    df[\"is_month_end\"] = df.index.is_month_end     # Binary feature for end of month\n",
        "    df[\"is_year_start\"] = df.index.is_year_start   # Binary feature for start of year\n",
        "    df[\"is_year_end\"] = df.index.is_year_end       # Binary feature for end of year\n",
        "\n",
        "    # Cyclical features (useful for capturing seasonality patterns)\n",
        "    df[\"sin_dayofweek\"] = np.sin(2 * np.pi * df[\"dayofweek\"] / 7)  # Sine transformation for day of the week\n",
        "    df[\"cos_dayofweek\"] = np.cos(2 * np.pi * df[\"dayofweek\"] / 7)  # Cosine transformation for day of the week\n",
        "    df[\"sin_month\"] = np.sin(2 * np.pi * df[\"month\"] / 12)  # Sine transformation for month\n",
        "    df[\"cos_month\"] = np.cos(2 * np.pi * df[\"month\"] / 12)  # Cosine transformation for month\n",
        "\n",
        "    return df\n",
        "\n",
        "df = create_features(df_google)"
      ],
      "metadata": {
        "id": "fYHrJ8Ywvsw8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a larger figure size and style\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "sns.set_style(\"whitegrid\")  # Set the background style to whitegrid for a cleaner look\n",
        "\n",
        "# Use a color palette for the boxplot\n",
        "sns.boxplot(data=df, x=\"dayofweek\", y=\"peak_bandwidth_utilization\", ax=ax, palette=\"coolwarm\")  # Adjust color with a palette\n",
        "\n",
        "# Add a title and style it\n",
        "ax.set_title(\"Bandwidth Usage by Day\", fontsize=18, fontweight=\"bold\", color=\"darkblue\")\n",
        "\n",
        "# Customize the x and y axis labels\n",
        "ax.set_xlabel(\"Day\", fontsize=14, color=\"darkblue\")\n",
        "ax.set_ylabel(\"Peak Bandwidth Usage\", fontsize=14, color=\"darkblue\")\n",
        "\n",
        "# Add gridlines for better readability\n",
        "ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "\n",
        "# Remove the top and right spines to give the plot a cleaner look\n",
        "sns.despine(top=True, right=True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qXjQeWqxwDpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 5))  # Use plt.subplots instead of plt.subplot\n",
        "sns.boxplot(data=df, x=\"month\", y=\"peak_bandwidth_utilization\", ax=ax)  # Pass ax to sns.boxplot\n",
        "ax.set_title(\"Bandwidth Consumption by Month\")\n",
        "ax.set_xlabel(\"Month\")  # Optional: Label the x-axis\n",
        "ax.set_ylabel(\"Bandwidth Consumption (GB)\")  # Optional: Label the y-axis\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pTkOBC1cxQDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply feature engineering to train and test sets\n",
        "train = create_features(train)\n",
        "test = create_features(test)\n",
        "\n",
        "# Define features and target\n",
        "TARGET = \"peak_bandwidth_utilization\"\n",
        "FEATURES = [\n",
        "    \"dayofweek\", \"month\",\n",
        "    \"dayofmonth\", \"is_weekend\", \"is_friday\", \"is_month_start\",\n",
        "    \"is_month_end\",\"is_year_start\",\n",
        "    \"is_year_end\", \"sin_dayofweek\", \"cos_dayofweek\",\n",
        "    \"sin_month\", \"cos_month\"\n",
        "]\n",
        "\n",
        "X_train = train[FEATURES]\n",
        "y_train = train[TARGET]\n",
        "X_test = test[FEATURES]\n",
        "y_test = test[TARGET]"
      ],
      "metadata": {
        "id": "MnN4M997xedD"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppress Optuna's output by setting the logging level to WARNING\n",
        "optuna.logging.set_verbosity(logging.WARNING)\n",
        "\n",
        "# Optuna objective function for hyperparameter tuning\n",
        "def objective(trial):\n",
        "    \"\"\"\n",
        "    Defines the objective function for Optuna hyperparameter tuning of the XGBRegressor model.\n",
        "\n",
        "    Parameters:\n",
        "    - trial: An Optuna Trial object which suggests values for the hyperparameters.\n",
        "\n",
        "    Returns:\n",
        "    - rmse: The Root Mean Squared Error (RMSE) on the test set, used as the objective to minimize.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the hyperparameters with search spaces for Optuna to optimize\n",
        "    param = {\n",
        "        \"n_estimators\": 1000,  # Set a high number of estimators, allowing early stopping to determine optimal rounds\n",
        "        \"early_stopping_rounds\": 50,  # Stops training if there's no improvement for 50 rounds\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 0.1, log=True),  # Controls step size, log scale\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),  # Limits tree depth to control complexity\n",
        "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),  # Minimum sum of weights in a child node\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),  # Fraction of data for each tree to avoid overfitting\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),  # Fraction of features per tree\n",
        "        \"gamma\": trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True),  # Minimum loss reduction for split, log scale\n",
        "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 10.0, log=True),  # L2 regularization, log scale\n",
        "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 10.0, log=True),  # L1 regularization, log scale\n",
        "        \"eval_metric\": \"rmse\"  # Evaluation metric set to RMSE (Root Mean Squared Error)\n",
        "    }\n",
        "\n",
        "    # Initialize the XGBRegressor model with the suggested hyperparameters\n",
        "    model = xgb.XGBRegressor(**param)\n",
        "\n",
        "    # Fit the model on the training set, with the validation set for early stopping\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_test, y_test)],  # Use test set as a validation set for early stopping\n",
        "        verbose=False  # Suppress output to keep the output clean\n",
        "    )\n",
        "\n",
        "    # Predict on the test set and calculate RMSE as the objective value\n",
        "    preds = model.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, preds))  # Calculate RMSE to evaluate model performance\n",
        "\n",
        "    return rmse  # Return RMSE as the value to be minimized by Optuna\n",
        "\n",
        "# Run Optuna optimization\n",
        "study = optuna.create_study(direction=\"minimize\")  # Create an Optuna study to minimize RMSE\n",
        "study.optimize(objective, n_trials=50)  # Run 50 trials of hyperparameter optimization\n",
        "\n",
        "# Train final model with best parameters\n",
        "# Retrieve the best parameters found by Optuna and set additional fixed parameters\n",
        "best_params = study.best_params\n",
        "best_params[\"n_estimators\"] = 1000\n",
        "best_params[\"early_stopping_rounds\"] = 50\n",
        "best_params[\"eval_metric\"] = \"rmse\"\n",
        "\n",
        "# Initialize and train the final model using the best-found hyperparameters\n",
        "model = xgb.XGBRegressor(**best_params)\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_test, y_test)],  # Use the test set as a validation set for early stopping\n",
        "    verbose=False  # Suppress output for a clean log\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "# Generate predictions on the test set and calculate the RMSE to assess performance\n",
        "preds = model.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "print(\"Test RMSE:\", rmse)  # Print the final RMSE on the test set\n",
        "\n",
        "# Plot feature importance\n",
        "# Visualize the top 10 most important features to understand which features contributed most to the model's predictions\n",
        "xgb.plot_importance(model, importance_type=\"weight\", max_num_features=10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XBmPFcL7x71Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set and add them as a new column in test\n",
        "test['Bandwidth_Prediction'] = model.predict(X_test)  # Assuming 'model' is your trained model\n",
        "\n",
        "# Concatenate the test set with predictions and the training set\n",
        "bandwidth_all = pd.concat([train, test], sort=False)\n",
        "\n",
        "# Plot the actual vs. predicted energy consumption with improved styling\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "\n",
        "# Plot the actual values with a solid line\n",
        "bandwidth_all['peak_bandwidth_utilization'].plot(ax=ax, color='#1f77b4', linewidth=2, label='Actual Usage')\n",
        "\n",
        "# Plot the predicted values with a dashed line for distinction\n",
        "bandwidth_all['Bandwidth_Prediction'].plot(ax=ax, color='#ff7f0e', linestyle='--', linewidth=2, label='Predicted MW')\n",
        "\n",
        "# Customize x and y labels\n",
        "ax.set_xlabel(\"Date\", fontsize=12, labelpad=10)\n",
        "ax.set_ylabel(\"Bandwidth Usage\", fontsize=12, labelpad=10)\n",
        "\n",
        "# Set a title with larger font and padding\n",
        "ax.set_title(\"Actual vs Predicted Bandwidth Consumption\", fontsize=16, fontweight='bold', pad=20)\n",
        "\n",
        "# Adjust the legend for clarity\n",
        "ax.legend(loc=\"upper left\", fontsize=10, frameon=True, title=\"Legend\")\n",
        "\n",
        "# Enable grid with light color for readability\n",
        "ax.grid(True, linestyle='--', color='grey', alpha=0.5)\n",
        "\n",
        "# Highlight a specific period, if needed (optional)\n",
        "#highlight_start, highlight_end = \"2015-01-01\", \"2015-02-01\"\n",
        "#ax.axvspan(highlight_start, highlight_end, color=\"black\", alpha=0.1, label=\"Highlighted Period\")\n",
        "\n",
        "# Add annotations for peak or significant points (optional)\n",
        "peak_date = bandwidth_all['peak_bandwidth_utilization'].idxmax()  # Find date of max bandwidth usage\n",
        "peak_value = bandwidth_all['peak_bandwidth_utilization'].max()    # Find max bandwidth usage value\n",
        "ax.annotate(\n",
        "    f\"Peak: {int(peak_value)} GB\",\n",
        "    xy=(peak_date, peak_value),\n",
        "    xycoords=\"data\",\n",
        "    xytext=(peak_date, peak_value + 10),  # Adjust annotation position\n",
        "    arrowprops=dict(arrowstyle=\"->\", color=\"red\", lw=1.5),\n",
        "    fontsize=10,\n",
        "    bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"red\", facecolor=\"white\", alpha=0.8)\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t16D0Tr0yVRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "id": "3WZ8FlAyeEEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for Mean Absolute Percentage Error (MAPE)\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    \"\"\"Calculates MAPE given y_true and y_pred\"\"\"\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "# Calculate error metrics on the test set\n",
        "rmse = mean_squared_error(y_true=test['peak_bandwidth_utilization'], y_pred=test['Bandwidth_Prediction'])\n",
        "mae = mean_absolute_error(y_true=test['peak_bandwidth_utilization'], y_pred=test['Bandwidth_Prediction'])\n",
        "mape = mean_absolute_percentage_error(y_true=test['peak_bandwidth_utilization'], y_pred=test['Bandwidth_Prediction'])\n",
        "\n",
        "print(f\"Our RMSE error is {rmse:.2f}\")\n",
        "print(f\"Our MAE error is {mae:.2f}\")\n",
        "print(f\"Our MAPE error is {mape:.2f}%\")"
      ],
      "metadata": {
        "id": "0lJDmF3WdHvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numbers import Number\n",
        "# Calculate error columns\n",
        "test['error'] = test['peak_bandwidth_utilization'] - test['Bandwidth_Prediction']\n",
        "test['abs_error'] = test['error'].abs()\n",
        "\n",
        "# Group errors by day and calculate mean errors\n",
        "#error_by_day = test.groupby(['month', 'dayofmonth'])[test.select_dtypes(include='number').columns()].mean()[['peak_bandwidth_utilization', 'Bandwidth_Prediction', 'error', 'abs_error']]\n",
        "error_by_day = (\n",
        "    test.groupby(['month', 'dayofmonth'])\n",
        "        [test.select_dtypes(include='number').columns]  # keep only numeric columns\n",
        "        .mean()\n",
        ")\n",
        "error_by_day = error_by_day[['peak_bandwidth_utilization',\n",
        "                             'Bandwidth_Prediction',\n",
        "                             'error',\n",
        "                             'abs_error']]\n",
        "\n",
        "# Display top 10 over-forecasted days\n",
        "over_forecasted_days = error_by_day.sort_values('error').head(10)\n",
        "print(\"Top 10 Over-Forecasted Days:\")\n",
        "display(over_forecasted_days)\n",
        "\n",
        "# Display top 10 worst absolute predicted days\n",
        "worst_predicted_days = error_by_day.sort_values('abs_error', ascending=False).head(10)\n",
        "print(\"\\nTop 10 Worst Absolute Predicted Days:\")\n",
        "display(worst_predicted_days)\n",
        "\n",
        "# Display top 10 best predicted days\n",
        "best_predicted_days = error_by_day.sort_values('abs_error').head(10)\n",
        "print(\"\\nTop 10 Best Predicted Days:\")\n",
        "display(best_predicted_days)"
      ],
      "metadata": {
        "id": "B1S4xmV-ez2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Future Forecast (Adjust N_DAYS as needed) ===\n",
        "# Uses the trained `model` and the same feature engineering to predict future peak_bandwidth_utilization.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Safety checks\n",
        "assert 'model' in globals(), \"Trained model `model` not found. Run the training cells first.\"\n",
        "assert 'df' in globals() and isinstance(df, pd.DataFrame), \"`df` not found.\"\n",
        "assert 'df_google' in globals(), \"`df_google` not found. Re-run data filtering cell.\"\n",
        "assert 'create_features' in globals(), \"`create_features` function not found.\"\n",
        "\n",
        "# Number of future days to predict\n",
        "N_DAYS = 14  # <-- change this\n",
        "\n",
        "# Determine the last date from the filtered subset\n",
        "last_date = pd.to_datetime(df_google.index.max())\n",
        "\n",
        "# Build empty frame with just an index of future dates\n",
        "future_index = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=N_DAYS, freq=\"D\")\n",
        "future_base = pd.DataFrame(index=future_index)\n",
        "\n",
        "# create_features expects the same schema as df_google; minimally we only need a datetime index\n",
        "# so we can pass an empty frame and rely on create_features to add derived columns\n",
        "future_feats = create_features(future_base.copy())\n",
        "\n",
        "# Determine the feature columns used by the model\n",
        "if hasattr(model, \"feature_names_in_\"):\n",
        "    feature_cols = list(model.feature_names_in_)\n",
        "else:\n",
        "    # Fallback: remove the known target if present, keep numerics\n",
        "    candidate_cols = future_feats.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    feature_cols = [c for c in candidate_cols if c != \"peak_bandwidth_utilization\"]\n",
        "\n",
        "# Align columns\n",
        "X_future = future_feats.reindex(columns=feature_cols)\n",
        "\n",
        "# Predict\n",
        "y_future = model.predict(X_future)\n",
        "\n",
        "# Assemble results\n",
        "forecast_df = pd.DataFrame({\n",
        "    \"predicted_peak_bandwidth_utilization\": y_future\n",
        "}, index=future_index)\n",
        "\n",
        "display(forecast_df)\n",
        "\n",
        "# Optional: quick plot\n",
        "ax = forecast_df[\"predicted_peak_bandwidth_utilization\"].plot(title=\"Forecast: next {} days\".format(N_DAYS), figsize=(12,4))\n",
        "ax.set_xlabel(\"Date\")\n",
        "ax.set_ylabel(\"Predicted peak bandwidth (Gbps)\")\n"
      ],
      "metadata": {
        "id": "t-B4nTVbkqXf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}