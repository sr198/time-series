{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Bandwidth Prediction with Exogenous Events\n",
    "This notebook demonstrates the enhanced bandwidth prediction system using shared modules and exogenous event features.\n",
    "\n",
    "## Features\n",
    "- Shared feature engineering modules\n",
    "- Exogenous event processing\n",
    "- Multi-combination model support\n",
    "- Enhanced temporal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "!pip install optuna xgboost scikit-learn pandas numpy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Add src to path to import our modules\n",
    "sys.path.append(os.path.join('..'))  # Go up one level from notebooks/\n",
    "\n",
    "# Import our custom modules\n",
    "from src.data.loader import BandwidthDataLoader\n",
    "from src.models.trainer import BandwidthModelTrainer\n",
    "from src.models.predictor import BandwidthPredictor\n",
    "from src.features.temporal_features import get_temporal_feature_names\n",
    "from src.features.event_features import get_event_feature_names\n",
    "\n",
    "# Set visualization style\n",
    "color_pal = sns.color_palette()\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "print(\"âœ… Enhanced Bandwidth Prediction System Loaded!\")\n",
    "print(\"ğŸ“Š Using shared modules for consistency with the application\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Data Loader\n",
    "Load bandwidth data and events with our enhanced data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader with events\n",
    "bandwidth_file = '../sample_data/internet_details.csv'\n",
    "events_file = '../sample_data/internet_event_details.csv'\n",
    "\n",
    "data_loader = BandwidthDataLoader(bandwidth_file, events_file)\n",
    "\n",
    "print(\"ğŸ“‚ Data loader initialized with:\")\n",
    "print(f\"   ğŸ“Š Bandwidth file: {bandwidth_file}\")\n",
    "print(f\"   ğŸ“… Events file: {events_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Available Combinations\n",
    "See what item/service_type combinations are available in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get available combinations\n",
    "combinations = data_loader.get_available_combinations()\n",
    "\n",
    "print(\"ğŸŒ Available Item/Service Type Combinations:\")\n",
    "print(\"-\" * 60)\n",
    "for i, (item, service_type) in enumerate(combinations, 1):\n",
    "    print(f\"{i:2d}. {item:<25} | {service_type}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Total combinations: {len(combinations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Analyze Data for Google/Cache\n",
    "Let's focus on the Google/Cache combination as in the original notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for Google/Cache combination\n",
    "item = 'Google'\n",
    "service_type = 'cache'\n",
    "\n",
    "# Prepare training data with enhanced features\n",
    "train_df, test_df = data_loader.prepare_training_data(\n",
    "    item=item,\n",
    "    service_type=service_type,\n",
    "    train_end_date='2025-08-22',\n",
    "    include_events=True,\n",
    "    lookback_days=7\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“Š Data for {item}/{service_type}:\")\n",
    "print(f\"   ğŸ“ˆ Training samples: {len(train_df)}\")\n",
    "print(f\"   ğŸ§ª Test samples: {len(test_df)}\")\n",
    "print(f\"   ğŸ“… Training period: {train_df.index.min()} to {train_df.index.max()}\")\n",
    "print(f\"   ğŸ“… Test period: {test_df.index.min()} to {test_df.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample of the enhanced data\n",
    "print(\"ğŸ“‹ Sample of Enhanced Data with Events:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"First 5 rows:\")\n",
    "display(train_df.head())\n",
    "\n",
    "print(\"\\nLast 5 rows:\")\n",
    "display(train_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Analysis\n",
    "Examine the temporal and event features we've created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature information\n",
    "temporal_features = get_temporal_feature_names()\n",
    "event_features = get_event_feature_names(lookback_days=7)\n",
    "all_features = data_loader.get_feature_columns(include_events=True, lookback_days=7)\n",
    "\n",
    "print(\"ğŸ”§ Feature Engineering Summary:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"ğŸ“… Temporal features: {len(temporal_features)}\")\n",
    "print(f\"ğŸ“Š Event features: {len(event_features)}\")\n",
    "print(f\"ğŸ¯ Total features: {len(all_features)}\")\n",
    "\n",
    "print(\"\\nğŸ“… Temporal Features:\")\n",
    "for feature in temporal_features:\n",
    "    print(f\"   â€¢ {feature}\")\n",
    "\n",
    "print(\"\\nğŸ“Š Event Features (sample):\")\n",
    "for feature in event_features[:10]:  # Show first 10\n",
    "    print(f\"   â€¢ {feature}\")\n",
    "if len(event_features) > 10:\n",
    "    print(f\"   ... and {len(event_features) - 10} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Data with Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train and test for visualization\n",
    "combined_df = pd.concat([train_df, test_df], sort=False)\n",
    "\n",
    "# Plot bandwidth usage with train/test split\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "# Plot training and test sets\n",
    "train_df['peak_bandwidth_utilization'].plot(\n",
    "    ax=ax, label='Training Set', color='blue', linewidth=2\n",
    ")\n",
    "test_df['peak_bandwidth_utilization'].plot(\n",
    "    ax=ax, label='Test Set', color='orange', linewidth=2\n",
    ")\n",
    "\n",
    "# Add split line\n",
    "split_date = '2025-08-22'\n",
    "ax.axvline(split_date, color='red', linestyle='--', linewidth=2, alpha=0.7)\n",
    "ax.text(split_date, ax.get_ylim()[1] * 0.9, 'Train/Test Split',\n",
    "        rotation=90, color='red', verticalalignment='center', fontweight='bold')\n",
    "\n",
    "# Customize plot\n",
    "ax.set_title(f'Enhanced {item}/{service_type} Bandwidth Usage with Events', \n",
    "             fontsize=16, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Date', fontsize=14)\n",
    "ax.set_ylabel('Peak Bandwidth Usage (Gbps)', fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"ğŸ“Š Dataset includes {len(combined_df)} total observations\")\n",
    "print(f\"ğŸ“ˆ Peak usage: {combined_df['peak_bandwidth_utilization'].max():.2f} Gbps\")\n",
    "print(f\"ğŸ“‰ Minimum usage: {combined_df['peak_bandwidth_utilization'].min():.2f} Gbps\")\n",
    "print(f\"ğŸ“Š Average usage: {combined_df['peak_bandwidth_utilization'].mean():.2f} Gbps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Event Analysis\n",
    "Analyze the impact of exogenous events on bandwidth usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have event features in our data\n",
    "event_cols = [col for col in combined_df.columns if col.startswith('event_')]\n",
    "capacity_cols = [col for col in combined_df.columns if 'capacity_change' in col]\n",
    "\n",
    "if event_cols:\n",
    "    print(\"ğŸ“… Event Impact Analysis:\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Count events by type\n",
    "    event_counts = {}\n",
    "    for col in event_cols:\n",
    "        count = combined_df[col].sum()\n",
    "        if count > 0:\n",
    "            event_type = col.replace('event_', '').replace('_recent_7d', ' (recent)')\n",
    "            event_counts[event_type] = count\n",
    "    \n",
    "    # Display event counts\n",
    "    print(\"ğŸ“Š Event occurrences:\")\n",
    "    for event_type, count in sorted(event_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"   â€¢ {event_type}: {count}\")\n",
    "    \n",
    "    # Capacity changes\n",
    "    if capacity_cols:\n",
    "        capacity_changes = combined_df[capacity_cols[0]]\n",
    "        total_increases = capacity_changes[capacity_changes > 0].sum()\n",
    "        total_decreases = abs(capacity_changes[capacity_changes < 0].sum())\n",
    "        \n",
    "        print(f\"\\nğŸ”§ Capacity Changes:\")\n",
    "        print(f\"   â¬†ï¸ Total increases: {total_increases:.0f} Gbps\")\n",
    "        print(f\"   â¬‡ï¸ Total decreases: {total_decreases:.0f} Gbps\")\n",
    "        print(f\"   ğŸ“Š Net change: {total_increases - total_decreases:.0f} Gbps\")\n",
    "else:\n",
    "    print(\"âŒ No event features found in the data.\")\n",
    "    print(\"   This might indicate an issue with event data loading.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Training with Enhanced Features\n",
    "Train the XGBoost model using our enhanced trainer with event features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model trainer\n",
    "trainer = BandwidthModelTrainer(data_loader)\n",
    "\n",
    "print(\"ğŸš€ Starting Enhanced Model Training\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"ğŸ¯ Target: {item}/{service_type}\")\n",
    "print(f\"ğŸ“Š Including exogenous events: âœ…\")\n",
    "print(f\"ğŸ“… Event lookback window: 7 days\")\n",
    "print(f\"ğŸ”§ Hyperparameter optimization: 30 trials\")\n",
    "print(\"\\nâ±ï¸ This may take a few minutes...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "training_results = trainer.train_model(\n",
    "    item=item,\n",
    "    service_type=service_type,\n",
    "    train_end_date='2025-08-22',\n",
    "    include_events=True,\n",
    "    lookback_days=7,\n",
    "    n_trials=30  # Reduced for notebook\n",
    ")\n",
    "\n",
    "# Display training results\n",
    "metrics = training_results['metrics']\n",
    "print(\"\\nğŸ¯ TRAINING RESULTS\")\n",
    "print(\"=\" * 25)\n",
    "print(f\"ğŸ“Š Test RMSE: {metrics['test_rmse']:.4f}\")\n",
    "print(f\"ğŸ“ Test MAE: {metrics['test_mae']:.4f}\")\n",
    "print(f\"ğŸ“ˆ Test MAPE: {metrics['test_mape']:.2f}%\")\n",
    "print(f\"ğŸ”§ Features used: {len(training_results['feature_columns'])}\")\n",
    "print(f\"âš¡ Best Optuna RMSE: {metrics['best_optuna_rmse']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "import xgboost as xgb\n",
    "\n",
    "model = training_results['model']\n",
    "\n",
    "# Create feature importance plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "xgb.plot_importance(model, importance_type=\"weight\", max_num_features=15, ax=ax)\n",
    "ax.set_title('Top 15 Feature Importance (Enhanced Model with Events)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Get feature importance as dataframe for analysis\n",
    "feature_importance = model.get_booster().get_score(importance_type='weight')\n",
    "importance_df = pd.DataFrame([\n",
    "    {'feature': k, 'importance': v} for k, v in feature_importance.items()\n",
    "]).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"ğŸ” Top 10 Most Important Features:\")\n",
    "print(\"-\" * 35)\n",
    "for i, row in importance_df.head(10).iterrows():\n",
    "    feature_type = \"ğŸ“… Temporal\" if row['feature'] in get_temporal_feature_names() else \"ğŸ“Š Event\"\n",
    "    print(f\"{feature_type:12} | {row['feature']:<25} | {row['importance']:>6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save the Enhanced Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_path = trainer.save_model(training_results)\n",
    "\n",
    "print(\"ğŸ’¾ Model Saved Successfully!\")\n",
    "print(f\"ğŸ“ File: {model_path}\")\n",
    "print(f\"ğŸ¯ Combination: {item}/{service_type}\")\n",
    "print(f\"ğŸ“Š Performance: {metrics['test_mape']:.2f}% MAPE\")\n",
    "print(f\"âœ… Ready for predictions via CLI or interactive app!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Make Predictions with Enhanced Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize predictor and make future predictions\n",
    "predictor = BandwidthPredictor(data_loader)\n",
    "\n",
    "# Make 14-day forecast\n",
    "future_predictions = predictor.predict_future(model_path, n_days=14)\n",
    "\n",
    "print(\"ğŸ”® 14-Day Future Forecast\")\n",
    "print(\"=\" * 30)\n",
    "display(future_predictions)\n",
    "\n",
    "# Plot predictions\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "future_predictions.set_index('date')['predicted'].plot(\n",
    "    ax=ax, marker='o', linewidth=2, markersize=6, color='green'\n",
    ")\n",
    "ax.set_title('14-Day Bandwidth Forecast (Enhanced Model with Events)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Predicted Bandwidth (Gbps)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "mean_pred = future_predictions['predicted'].mean()\n",
    "max_pred = future_predictions['predicted'].max()\n",
    "min_pred = future_predictions['predicted'].min()\n",
    "\n",
    "print(f\"\\nğŸ“Š Forecast Summary:\")\n",
    "print(f\"   ğŸ“ˆ Average: {mean_pred:.2f} Gbps\")\n",
    "print(f\"   â¬†ï¸ Maximum: {max_pred:.2f} Gbps\")\n",
    "print(f\"   â¬‡ï¸ Minimum: {min_pred:.2f} Gbps\")\n",
    "print(f\"   ğŸ“Š Range: {max_pred - min_pred:.2f} Gbps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Compare with Historical Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test historical predictions\n",
    "historical_results = predictor.predict_historical(\n",
    "    model_path, \n",
    "    start_date='2025-08-22', \n",
    "    end_date='2025-08-31'\n",
    ")\n",
    "\n",
    "print(\"ğŸ“Š Historical Prediction Performance\")\n",
    "print(\"=\" * 40)\n",
    "display(historical_results[['date', 'actual', 'predicted', 'error', 'abs_error']])\n",
    "\n",
    "# Plot actual vs predicted\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "historical_results.set_index('date')[['actual', 'predicted']].plot(\n",
    "    ax=ax, marker='o', linewidth=2, markersize=6\n",
    ")\n",
    "ax.set_title('Actual vs Predicted (Enhanced Model)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Bandwidth (Gbps)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(['Actual', 'Predicted'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Performance metrics\n",
    "rmse = (historical_results['error'] ** 2).mean() ** 0.5\n",
    "mae = historical_results['abs_error'].mean()\n",
    "mape = (historical_results['abs_error'] / historical_results['actual']).mean() * 100\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Historical Performance:\")\n",
    "print(f\"   ğŸ“ RMSE: {rmse:.4f}\")\n",
    "print(f\"   ğŸ“ MAE: {mae:.4f}\")\n",
    "print(f\"   ğŸ“Š MAPE: {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Integration with Production System\n",
    "\n",
    "This notebook demonstrates the enhanced bandwidth prediction system. The trained model is now available for use in the production application.\n",
    "\n",
    "### Using the CLI:\n",
    "```bash\n",
    "# Make future predictions\n",
    "python main.py predict --item \"Google\" --service-type \"cache\" --days 14\n",
    "\n",
    "# Predict for specific date\n",
    "python main.py predict --item \"Google\" --service-type \"cache\" --date \"2025-09-15\"\n",
    "```\n",
    "\n",
    "### Using the Interactive Interface:\n",
    "```bash\n",
    "python main.py interactive\n",
    "```\n",
    "\n",
    "### Key Enhancements:\n",
    "1. **ğŸ“Š Exogenous Event Features**: Network events, capacity changes, external factors\n",
    "2. **ğŸ”§ Shared Modules**: Consistent feature engineering across notebook and application\n",
    "3. **ğŸ¯ Multi-Combination Support**: Train models for any item/service_type combination\n",
    "4. **ğŸ’¾ Model Persistence**: Save and load trained models with metadata\n",
    "5. **ğŸš€ Production Ready**: CLI and interactive interfaces for end users"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}